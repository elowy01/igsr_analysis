ML-based workflow to filter a VCF
=================================

Filtering the spurious variants from a callset is a common task in variation studies using sequencing data.

Variant discovery methods are not perfect and will produce a certain number of false positive calls, specially if the sequencing data is either noisy or the depth of coverage is not enough to distinguish a real variant from a sequencing artifact.

This is why a method for identifying these false variants is necessary. Different methods have been developed for filtering and at the time of writing I would say that the most used is `GATK VQSR <https://www.ncbi.nlm.nih.gov/pubmed/20644199>`_ which works really well and is specially relevant for filtering the calls obtained with the GATK callers (UnifiedGenotyper [UG] and HaplotypeCaller [HC]).

VQSR relies on a sophisticated model that needs to be trained with the annotation profiles generated by UG or HC for the different variant sites and will also depend on the existence of reference datasets specifically formatted to be used with VQSR.

The problem arises when you need to filter a call set obtained using a non-GATK caller that does not have the variant annotations required by VQSR, or you are filtering a call set from a non-human organism, for which there is not a VQSR-formatted reference call set.

If you find yourself in this situation you might find this pipeline useful.

Filtering approach
------------------

This pipeline implements a supervised Machine Learning (ML) model in order to solve a binary classification problem.

It is supervised because it trains the model with a gold-standard call set for which we already know what variant sites are real
and it is a binary classification problem where we have multiple numerical independent variables (annotation values for each of the variant sites) to predict or classify a binary outcome: variant or non-variant site.

This particular type of problem can be modelled using a Logistic regression binary classifier, and more specifically, our pipeline uses the `Scikit-learn <https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.
LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression>`_ Python library implementation.

The pipeline needs to be run in different stages:

- Recursive Feature Elimination (RFE) stage (optional). This step is used to select the desired ``n`` number of annotations more informative for the variant classification process. Our pipeline uses the implementation from  `Scikit-learn RFE <https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html?highlight=rfe#sklearn.feature_selection.RFE>`_ and it works by recursively removing features (annotations), building a logistic regression model using the remaining attributes, and calculating the model accuracy. RFE is able to work out the combination of ``n`` attributes that contribute the most to the prediction.
- Training of the ML model. Our pipeline is capable of filtering SNPs and INDELs. These two variant types are characterized by two different annotation profiles, and this is why the pipeline will train two models for SNPs and INDELs respectively. This step requires high-confidence SNP and INDEL call sets along with the call set to be filtered, and it will generate two serialized trained models together with its estimated accuracy. 
- Finally, the pipeline will apply the SNPs/INDELs models obtained in the previous step and will filter the variants using a user-supplied sensitivity cutoff. This step will generate a single VCF file containing the filtered variants.

USAGE
-----

**This page is under construcion**
